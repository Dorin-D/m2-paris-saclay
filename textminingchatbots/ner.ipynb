{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to read BRAT and conll files\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_brat(folder_location):\n",
    "    ann_files = glob.glob(folder_location + \"*.ann\")\n",
    "    txt_files = glob.glob(folder_location + \"*.txt\")\n",
    "    #read ann files and ignore lines starting with #\n",
    "    ann_lines = dict()\n",
    "    for ann_file in ann_files:\n",
    "        current_lines = []\n",
    "        with open(ann_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if not line.startswith(\"#\"):\n",
    "                    current_lines.append(line)\n",
    "        ann_lines[ann_file] = \"\\n\".join(current_lines)\n",
    "\n",
    "    txt_lines = dict()\n",
    "    for txt_file in txt_files:\n",
    "        current_lines = []\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                current_lines.append(line)\n",
    "        txt_lines[txt_file] = \"\\n\".join(current_lines)\n",
    "\n",
    "    return ann_lines, txt_lines\n",
    "\n",
    "def process_annotations_brat(ann_lines_split):\n",
    "    #process the annotations into a dictionary of lists\n",
    "    #we want to get a dictionary count of tokens (entites split by space), a dictionary count of entities, and a dictionary count of entity types\n",
    "    count_entities = {}\n",
    "    count_tokens = {}\n",
    "    count_entity_types = {}\n",
    "\n",
    "    for line in ann_lines_split:\n",
    "        entity = line[1]\n",
    "        entity_type = line[0]\n",
    "        tokens = entity.split(\" \")\n",
    "        if entity in count_entities:\n",
    "            count_entities[entity] += 1\n",
    "        else:\n",
    "            count_entities[entity] = 1\n",
    "        for token in tokens:\n",
    "            if token in count_tokens:\n",
    "                count_tokens[token] += 1\n",
    "            else:\n",
    "                count_tokens[token] = 1\n",
    "        if entity_type in count_entity_types:\n",
    "            count_entity_types[entity_type] += 1\n",
    "        else:\n",
    "            count_entity_types[entity_type] = 1\n",
    "\n",
    "    # return total of tokens, total of entitities, total of unique entities, how many types we have and a dictionary of tokens per type count\n",
    "    return sum(count_tokens.values()), sum(count_entities.values()), len(count_entities), len(count_entity_types), count_entity_types, count_entities, count_tokens, count_entity_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_base = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed\"\n",
    "\n",
    "formats = [\"brat\"]\n",
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "subsets = [\"EMEA\", \"MEDLINE\"]\n",
    "\n",
    "# read BRAT corpus EMEA trainset\n",
    "train_EMEA_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/train/EMEA/\"\n",
    "train_MEDLINE_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/train/MEDLINE/\"\n",
    "dev_EMEA_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/dev/EMEA/\"\n",
    "dev_MEDLINE_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/dev/MEDLINE/\"\n",
    "test_EMEA_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/test/EMEA/\"\n",
    "test_MEDLINE_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/test/MEDLINE/\"\n",
    "\n",
    "\n",
    "for format in formats:\n",
    "    for split in splits:\n",
    "        for subset in subsets:\n",
    "            elif format == \"brat\":\n",
    "                folder = folder_base + \"_BRAT/corpus/\" + split + \"/\" + subset + \"/\"\n",
    "                ann_lines_split = read_brat(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ann_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read MSHFRE.csv\n",
    "french_mesh = pd.read_csv(\"MSHFRE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of preferred label and synonyms\n",
    "french_mesh_set = set(french_mesh['Preferred Label'])\n",
    "french_mesh_set.update(french_mesh[\"Synonyms\"][0:2].dropna().apply(lambda x: x.split(\"|\")).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29359"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(french_mesh_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
