{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7ae6e-373d-4304-ac29-d57acdc5caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets pandas matplotlib scikit-learn transformers rouge evaluate tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969196e-f1b5-41a3-bf21-c43bb4f006d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use google colab\n",
    "!wget https://gitlab.dsi.universite-paris-saclay.fr/thomas.gerald/textminingandchatbot/-/raw/469b1e352a5a65a743aeb13b9705157e341fc21e/tp/TP-2/TP-2-data.zip\n",
    "!unzip TP-2-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22649f2d-b56e-4386-bb15-0b64cd1d79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm # The progress bar\n",
    "\n",
    "import torch # DeepLearning Framework\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM # Model repository\n",
    "from datasets import load_dataset # Dataset Repository\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af64aba0-7140-41bc-82f1-ab1d7f85a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# woz_dataset\n",
    "woz_dataset = load_dataset(\"multi_woz_v22\", trust_remote_code=True)\n",
    "training_set = woz_dataset['train']\n",
    "validation_set = woz_dataset['validation']\n",
    "test_set = woz_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee92c5-8bc0-4d04-9b2f-59c30e54ce64",
   "metadata": {},
   "source": [
    "# Build a task oriented chatbot\n",
    "\n",
    "In this miniproject we propose different tools to extract information. The objective is to develop a chatbot with possible extracted information. \n",
    "\n",
    "**A first step** would be to consider generating answer given the dialogue history and a dialogue act such as :\n",
    "```\n",
    "[history]\n",
    "'I need train reservations from norwich to cambridge',\n",
    "'I have 133 trains matching your request. Is there a specific day and time you would like to travel?',\n",
    "\"I'd like to leave on Monday and arrive by 18:00.\"\n",
    "[history]\n",
    "```\n",
    "`[dialogue_act]train_choice 12[end_dialogue_act]`\n",
    "\n",
    "Generate an answer such as :\n",
    "\n",
    "```There are 12 trains for the day and time you request. Would you like to book it now?```\n",
    "\n",
    "Thos results should be compared to the approach proposed previous week.\n",
    "\n",
    "**In a second time** you should take inspiration from the article proposed in the directory to propose an approach that do not use ground truth to generate answer, but contrary to last week, take into account data located in the database. Notice for this step, it is not expected to get very good performances. Depending on your progress you can only consider generating delexicalised sentence i.e. sentences without database entry value. For instance you could predict such a sentence : \n",
    "\n",
    "```There are [train_choice] trains meeting your needs with the first leaving at [train_leaveat] and the last one leaving at [train_leaveat]```\n",
    "\n",
    "Notice to formulate consistent answer information from database are still required "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7698b-cf95-4853-bb33-c78d53ee5fa5",
   "metadata": {},
   "source": [
    "## 1. Available tools and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47264135-682a-49f5-b38e-c6ef7bc4e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from woz_tools import MultiWoZDatabase, MultiWoZTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b3a98-9bb6-4e9b-9a71-1f53436b7cc8",
   "metadata": {},
   "source": [
    "### Access to dialogue state\n",
    "To access the dialogue state two function are made available :\n",
    "* `encode_frame_state(state)` : encoding a state into a characters string \n",
    "* `decode_frame_state(str_state)` : decoding the char string to a list (for instance to query the database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85953a4e-29f3-46b1-8b4d-0508cb575d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering the following state : \n",
      "\n",
      " x = [{'active_intent': 'find_hotel', 'requested_slots': ['hotel-name'], 'slots_values': {'slots_values_name': ['hotel-area', 'hotel-pricerange'], 'slots_values_list': [['centre'], ['cheap']]}}]\n",
      "\n",
      "\n",
      "MultiWoZState.encode_frame_state(state) : \n",
      "\n",
      "\"[state][intent:find_hotel][hotel-area:['centre']][hotel-pricerange:['cheap']][end_intent][end_state]\"\n",
      "\n",
      "\n",
      "MultiWoZState.encode_frame_state(encoded_state) : \n",
      "\n",
      " [{'active_intent': 'find_hotel', 'slots_values': {'slots_values_name': ['hotel-area', 'hotel-pricerange'], 'slots_values_list': [['centre'], ['cheap']]}}]\n"
     ]
    }
   ],
   "source": [
    "# let consider the following example\n",
    "x = training_set[50]['turns']['frames'][4]['state']\n",
    "print(f'Considering the following state : \\n\\n x = {x}\\n\\n')\n",
    "y = MultiWoZTools.encode_frame_state(x)\n",
    "print(f'MultiWoZState.encode_frame_state(state) : \\n\\n\"{y}\"\\n\\n')\n",
    "z = MultiWoZTools.decode_frame_state(y)\n",
    "print(f'MultiWoZState.encode_frame_state(encoded_state) : \\n\\n {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1deec2-813e-4ace-b19d-b0276d0ef95c",
   "metadata": {},
   "source": [
    "### Access to dialogue act\n",
    "For the dialogue act the following function is designed :\n",
    "* `encode_dialogue_act` : encoding a dialogue act into a characters string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d6d66d-7454-4eeb-91bc-c0c5bf929252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[dialogue_act]hotel_choice 3,hotel_name bridge guest house,hotel_name hamilton lodge,hotel_name hobsons house[end_dialogue_act]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_act = test_set[85]['turns']['dialogue_acts'][5]\n",
    "MultiWoZTools.encode_dialogue_act(dialogue_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d87fbf7-c681-4bf6-b4a2-f7548e512a34",
   "metadata": {},
   "source": [
    "*Using the dialogue act and the correct utterance we can* **delexicalize the utterance** with the function\n",
    "* `MultiWoZState.delexicalize_answer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8fc453-1b2a-406e-8ff6-e3c7da76ad07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, there are [hotel_choice]: [hotel_name], [hotel_name], and [hotel_name].'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance = test_set[85]['turns']['utterance'][5]\n",
    "MultiWoZTools.delexicalize_answer(utterance, dialogue_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743c6b3-b6b8-45bf-abb7-502ceb9db122",
   "metadata": {},
   "source": [
    "## Tansform the state into query\n",
    "The database of the dataset is composed of different json file in the `data/db` folder :\n",
    "* attraction_db.json\n",
    "* hospital_db.json\n",
    "* police_db.json\n",
    "* taxi_db.json\n",
    "* bus_db.json\n",
    "* hotel_db.json\n",
    "* restaurant_db.json\n",
    "* train_db.json\n",
    "\n",
    "You can load the dataset using the `MultiWoZDatabase` object and query the database by using the `search` method. A query is in the following format : \n",
    "\n",
    "```\n",
    "[\n",
    "    (\"domain_1\",[\n",
    "        (\"field_1\",\"=\",[values_1, values_2]),\n",
    "        (\"field_2\",\"=\",[\"value_1\"])\n",
    "    ])\n",
    "    (\"domain_2\",[\n",
    "        ...\n",
    "    ])\n",
    "]\n",
    "```\n",
    "\n",
    "You can also create a query from a state using the `state_to_db` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42253710-bead-4191-b191-0ba5c1d23b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiwoz_db = MultiWoZDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e831363-956d-4c5b-ba18-1beb1c8ec3c6",
   "metadata": {},
   "source": [
    "#### Exemple building a query from state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09497d29-4a46-42b5-887b-0d578cfda259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hotel', [('area', '=', ['centre']), ('pricerange', '=', ['cheap'])])]\n"
     ]
    }
   ],
   "source": [
    "# let consider the following example\n",
    "x = training_set[50]['turns']['frames'][4]['state']\n",
    "query = MultiWoZTools.state_to_db(x)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491f067-f30d-47c8-9e67-75297df75a3e",
   "metadata": {},
   "source": [
    "#### Exemple querying the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ab1562-4b58-4511-90c6-dea928a4df34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hotel',\n",
       "  (2,\n",
       "   [{'address': '56 saint barnabas road',\n",
       "     'area': 'centre',\n",
       "     'internet': 'yes',\n",
       "     'parking': 'yes',\n",
       "     'id': '2',\n",
       "     'location': [52.1986444444444, 0.138133333333333],\n",
       "     'name': 'alexander bed and breakfast',\n",
       "     'phone': '01223525725',\n",
       "     'postcode': 'cb12de',\n",
       "     'price': {'double': '50', 'single': '40'},\n",
       "     'pricerange': 'cheap',\n",
       "     'stars': '4',\n",
       "     'takesbookings': 'yes',\n",
       "     'type': 'guesthouse'},\n",
       "    {'address': '41 warkworth street',\n",
       "     'area': 'centre',\n",
       "     'internet': 'yes',\n",
       "     'parking': 'yes',\n",
       "     'id': '15',\n",
       "     'location': [52.20439812598512, 0.13059139251708984],\n",
       "     'name': 'el shaddai',\n",
       "     'phone': '01223327978',\n",
       "     'postcode': 'cb11eg',\n",
       "     'price': {'double': '60', 'family': '62', 'single': '40'},\n",
       "     'pricerange': 'cheap',\n",
       "     'stars': '0',\n",
       "     'takesbookings': 'yes',\n",
       "     'type': 'guesthouse'}]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiwoz_db.search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e79ab-0018-433c-b740-aa236643a91d",
   "metadata": {},
   "source": [
    "## 2. Generation with ground truth dialogue act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7016cf9-a809-409f-aa3c-86e86b7570f6",
   "metadata": {},
   "source": [
    "#### Fill the dataset object to give the previous utterance and the dialogue act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9dc4a2-4445-4551-9630-acbc0a0b8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MultiWoZDataset:\n",
    "    def __init__(self, dataset, database, history_size=5):\n",
    "        self.dataset = dataset\n",
    "        self.database = database\n",
    "        self.history_size = history_size\n",
    "        self.index = []\n",
    "        for i, dial in enumerate(dataset):\n",
    "            for j, speaker in enumerate(dial['turns']['speaker']):\n",
    "                if speaker == 1:\n",
    "                    self.index.append((i,j))\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "       pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26dbd579-1970-4d7a-92b5-9ab3e9aa5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_train = MultiWoZDataset(training_set, multiwoz_db)\n",
    "mw_valid = MultiWoZDataset(validation_set, multiwoz_db)\n",
    "mw_test = MultiWoZDataset(test_set, multiwoz_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76a79cb-41a3-4008-b342-7147b68850b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"[USER]:I need train reservations from norwich to cambridge[BOT]I have 133 trains matching your request. Is there a specific day and time you would like to travel?[USER]:I'd like to leave on Monday and arrive by 18:00.\",\n",
       " 'label': 'There are 12 trains for the day and time you request. Would you like to book it now?',\n",
       " 'act': '[dialogue_act]train_choice 12[end_dialogue_act]',\n",
       " 'label_delex': 'There are [train_choice] trains for the day and time you request. Would you like to book it now?',\n",
       " 'db': '[db][result:train:4][end_db]',\n",
       " 'state': \"[state][intent:find_train][train-arriveby:['18:00']][train-day:['monday']][train-departure:['norwich']][train-destination:['cambridge']][end_intent][end_state]\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df7117-5d5d-4705-9ce9-db741005b73d",
   "metadata": {},
   "source": [
    "An example of output (for this part only history, label and act are necessary). Notice that history return all the previous `history_size` turn !!!\n",
    "```\n",
    "{'history': \"[USER]:I need train reservations from norwich to cambridge[BOT]I have 133 trains matching your request. Is there a specific day and time you would like to travel?[USER]:I'd like to leave on Monday and arrive by 18:00.\",\n",
    " 'label': 'There are 12 trains for the day and time you request. Would you like to book it now?',\n",
    " 'act': '[dialogue_act]train_choice 12[end_dialogue_act]',\n",
    " 'label_delex': 'There are [train_choice] trains for the day and time you request. Would you like to book it now?',\n",
    " 'db': '[db][result:train:4][end_db]',\n",
    " 'state': \"[state][intent:find_train][train-arriveby:['18:00']][train-day:['monday']][train-departure:['norwich']][train-destination:['cambridge']][end_intent][end_state]\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281bc83-9955-47a8-ade5-ddc313f4328f",
   "metadata": {},
   "source": [
    "### Defining the model and the dataset\n",
    "\n",
    "We will consider as model the distilgpt2 model, a distilled model of gpt2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ea8b4a5-56d1-4b32-abe8-4776dcd59567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '<|endoftext|>'})\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad7d6b-4413-49d3-9ae2-c78fb309c58a",
   "metadata": {},
   "source": [
    "define now a class `WoZActDataset` that take the previous dataset in the constructor and return in getitem data in the following format: \n",
    "\n",
    "```\n",
    "\"[USER]:i need a place to dine in the center thats expensive[BOT]I have several options for you; do you prefer African, Asian, or British food?[USER]:Any sort of food would be fine, as long as it is a bit expensive. Could I get the phone number for your recommendation?[dialogue_act]restaurant_food Afrian,restaurant_name Bedouin,restaurant_area centre[end_dialogue_act][ANSWER]There is an Afrian place named Bedouin in the centre. How does that sound?\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1bd37a5-787a-4dd0-b4df-bba65042a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoZActDataset(Dataset):\n",
    "    def __init__(self, multiwoz_dataset, training=True):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.multiwoz_dataset)\n",
    "\n",
    "class TokenizerCollator(Dataset):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return self.tokenizer(data, return_tensors='pt', padding=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41c9a745-7830-4f87-9608-c9635daa763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = WoZActDataset(mw_train)\n",
    "valid = WoZActDataset(mw_valid)\n",
    "test = WoZActDataset(mw_test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "455c5c9c-45c0-44cf-88e5-ce1998a0abc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[USER]:i need a place to dine in the center thats expensive[BOT]I have several options for you; do you prefer African, Asian, or British food?[USER]:Any sort of food would be fine, as long as it is a bit expensive. Could I get the phone number for your recommendation?[dialogue_act]restaurant_food Afrian,restaurant_name Bedouin,restaurant_area centre[end_dialogue_act][ANSWER]There is an Afrian place named Bedouin in the centre. How does that sound?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbb71aa-f4da-48a3-bff3-79e4b7aa04d2",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Below complete the function validation for the training which will print the validation loss. Do not hesitate to copy part of the code !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16a0f7b5-d244-46cd-82f1-4a157cd68791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, padding_idx=100):\n",
    "        self.model = model\n",
    "        self.optimizer = None\n",
    "\n",
    "    def at_training_start(self, learning_rate = 1e-3):\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=50257)\n",
    "\n",
    "    def training_step(self, data):\n",
    "        y_pred = self.model(**data)\n",
    "        y_truth = data[\"input_ids\"][:, 1:].flatten()\n",
    "\n",
    "        loss_reconstruction = self.criterion(y_pred.logits[:,:-1].reshape(y_truth.shape[0], -1), y_truth)\n",
    "        (loss_reconstruction).backward()\n",
    "        return loss_reconstruction.item()\n",
    "\n",
    "\n",
    "    def validation(self, validation_dl, use_gpu=False, iter_count=None):\n",
    "        pass\n",
    "        \n",
    "    def fit(self,\n",
    "            training_dl,\n",
    "            validation_dl,\n",
    "            learning_rate = 1e-3,\n",
    "            validation_frequency = 8,\n",
    "            max_iter = 10000,\n",
    "            use_gpu=False,\n",
    "\n",
    "        ):\n",
    "        if(use_gpu):\n",
    "          self.model = self.model.cuda()\n",
    "        self.at_training_start(learning_rate)\n",
    "\n",
    "        iter_count = 0\n",
    "        loss_buffer = []\n",
    "        pbar = trange(max_iter)\n",
    "\n",
    "        while(iter_count < max_iter):\n",
    "            for data in training_dl:\n",
    "                if use_gpu:\n",
    "                    data = {k:v.cuda() for k, v in data.items()}\n",
    "                self.optimizer.zero_grad()\n",
    "                loss_buffer += [self.training_step(data)]\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if(iter_count  % validation_frequency == 0):\n",
    "                    print(\"Loss at iteration %s is %s\"%(iter_count, np.mean(loss_buffer)))\n",
    "                    self.model.eval()\n",
    "                    self.validation(validation_dl, use_gpu=use_gpu, iter_count=iter_count)\n",
    "                    self.model.train()\n",
    "                    loss_buffer = []\n",
    "                iter_count += 1\n",
    "                pbar.update(1)\n",
    "                if(iter_count >= max_iter):\n",
    "                  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63f1db5e-9eef-4023-954d-babf8a07e872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9314957205e944e1b015fdf7581d1561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at iteration 0 is 6.794318675994873\n",
      "Loss validation at iteration 0 is 7.564188224412662\n",
      "Loss at iteration 1000 is 1.1781438655257226\n",
      "Loss validation at iteration 1000 is 0.9026029530541722\n",
      "Loss at iteration 2000 is 0.9880004197955131\n",
      "Loss validation at iteration 2000 is 0.8588697838060784\n",
      "Loss at iteration 3000 is 0.9366088448762894\n",
      "Loss validation at iteration 3000 is 0.8363133921767726\n",
      "Loss at iteration 4000 is 0.8963712045550346\n",
      "Loss validation at iteration 4000 is 0.8115563449405488\n",
      "Loss at iteration 5000 is 0.8778614881634712\n",
      "Loss validation at iteration 5000 is 0.8171859422287384\n",
      "Loss at iteration 6000 is 0.8606208698749542\n",
      "Loss validation at iteration 6000 is 0.7965945031219747\n",
      "Loss at iteration 7000 is 0.8513367728292942\n",
      "Loss validation at iteration 7000 is 0.7924642921526195\n",
      "Loss at iteration 8000 is 0.8053309039771557\n",
      "Loss validation at iteration 8000 is 0.7956381447903522\n",
      "Loss at iteration 9000 is 0.8048457061052322\n",
      "Loss validation at iteration 9000 is 0.7943362952310802\n"
     ]
    }
   ],
   "source": [
    "collator = TokenizerCollator(tokenizer)\n",
    "training_dl = DataLoader(train, batch_size=8, shuffle=True, collate_fn=collator, num_workers=2)\n",
    "validation_dl = DataLoader(valid, batch_size=32, shuffle=True, collate_fn=collator, num_workers=2)\n",
    "my_trainer = Trainer(model)\n",
    "my_trainer.fit(training_dl, validation_dl, validation_frequency=1000, use_gpu=True, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39759b0-d032-4a3a-a96c-f76daa3e60e7",
   "metadata": {},
   "source": [
    "## Prediction on the test set\n",
    "To predict you should use the `generate` method from the model:\n",
    "```\n",
    "model.generate(data['input_ids'], do_sample=False,\n",
    "                                max_length=512, pad_token_id=model.config.eos_token_id)\n",
    "```\n",
    " Notice if you do not have sufficient computational ressource, you can download the model at [huggingface](https://huggingface.co/ThomasGerald/multiwoz_with_ground_truth_act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49dcf9e-2c72-4786-ba82-1b730fd7a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly from hugging face\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21718272-7988-4a5f-a504-a7129d520560",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = TokenizerCollator(tokenizer)\n",
    "test_prediction = []\n",
    "test_dl = DataLoader(test, batch_size=8, shuffle=False, collate_fn=collator, num_workers=2)\n",
    "model.eval()\n",
    "use_gpu = True\n",
    "\n",
    "# predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3a951f2-cea3-408d-ab2f-5fc0cc4dd024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_generated_text = []\n",
    "for output_ids in test_prediction:\n",
    "    test_generated_text.append(tokenizer.decode(output_ids).split('[ANSWER]')[-1].replace('<|endoftext|>', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b7e240b-df1c-4a76-8100-342bb143d8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: Okay, your booking was successful! The reference number is MUFCMYFF . The table will be reserved for 15 minutes. \n",
      "Predicted: I was able to book that for you. Your reference number is MUFCMYFF. Is there anything else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "print('Ground truth: %s \\nPredicted: %s'%(mw_test[7]['label'], test_generated_text[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ad21e-de9a-4ae5-a590-22d6f0085c55",
   "metadata": {},
   "source": [
    "## Evaluate the model \n",
    "To evaluate the model you can use :\n",
    "* N-GRAM Methods such as ROUGE, BLEU or METEOR\n",
    "* Verify that act items are in the generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a67cd-d02a-427e-bbdd-159c78c62432",
   "metadata": {},
   "source": [
    "## 3. Generation with state and database [Optional]\n",
    "\n",
    "You should take inspiration from the article proposed in the directory to propose an approach that do not use ground truth to generate answer, but contrary to last week, take into account data located in the database. Notice for this step, it is not expected to get very good performances. Depending on your progress you can only consider generating delexicalised sentence i.e. sentences without database entry value. For instance you could predict such a sentence : \n",
    "\n",
    "```There are [train_choice] trains meeting your needs with the first leaving at [train_leaveat] and the last one leaving at [train_leaveat]```\n",
    "\n",
    "Notice to formulate consistent answer information from database are still required. Of course you can adapt the tools in the file woz_tools.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d97823-fe42-47cb-b811-3d38c387452f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
