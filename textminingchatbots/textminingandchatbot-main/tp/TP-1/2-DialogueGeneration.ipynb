{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student: Dorin Doncenco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVXycoM-vzC0",
    "outputId": "bde35f8e-ad8f-439d-eaaa-1d15b25b3f5c"
   },
   "outputs": [],
   "source": [
    "# ! pip install datasets pandas matplotlib scikit-learn transformers rouge evaluate tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4gMctwE0v12A"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm # The progress bar\n",
    "\n",
    "import torch # DeepLearning Framework\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM # Model repository\n",
    "from datasets import load_dataset # Dataset Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation for task oriented chatbot\n",
    "\n",
    "<img src=\"media/dialogue_patient.png\" style=\"width: 400px;\"/></div>\n",
    "The objective of this small project is to devellop a small chatbot using information of the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Getting started : Try a naive generative model\n",
    "<div style={width:10%}> In this first part we will try a naive model and \"play\" with this model. The model is a simple transformer (based on gpt2 model), it's objective given a user query to answer it in natural language.</div><div><img src=\"media/transformer-block.png\" alt=\"transformer architecture\" style=\"width: 400px;\"/></div>\n",
    "\n",
    "\n",
    "**Let's start to load the model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"ThomasGerald/wozchitchat\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ThomasGerald/wozchitchat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate from an input text with the model (try your own input) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED_TEXT : I would like a place located on the west side please.[BOT]There are no restaurants matching your criteria. Would you like me to try a different type of food?<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "text = \"I would\" # input text\n",
    "tokenized_text = tokenizer(text, return_tensors='pt') # we tokenize the text\n",
    "generated_token_ids = model.generate(**tokenized_text, do_sample=True,\n",
    "                                     max_length=200, pad_token_id=model.config.eos_token_id) # we generate the text (sampled)\n",
    "print(f'GENERATED_TEXT : {tokenizer.decode(generated_token_ids[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model as been ``Adapted'' using the following format :\n",
    "\n",
    "**[USER]{user_input}[BOT]{answer_of_the_system}**\n",
    "\n",
    "The model was trained to generate **{answer_of_the_system}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 : Create a interactive interface following the previous format\n",
    "\n",
    "Modify the following class to make an interactive chatbot using the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveChat(object):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def answer(self, current_input):\n",
    "        ''' return the answer of the chatbot\n",
    "        '''\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        output = self.model.generate(self.tokenizer(current_input, return_tensors='pt').input_ids, max_length=200, do_sample=True, pad_token_id=tokenizer.pad_token_id)\n",
    "        return self.tokenizer.decode(output[0])\n",
    "\n",
    "    def start(self):\n",
    "        current_answer = \"Start dialogue\"\n",
    "        current_input = \"\"\n",
    "        while(current_input != 'exit'):\n",
    "            current_input = input(\"Bot: \"+current_answer + \" \\nUser: \")\n",
    "            current_answer = self.answer(current_input)\n",
    "            print(\"_\"*50)\n",
    "            print(\"Bot: \"+current_answer)\n",
    "            print(\"_\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________\n",
      "Bot: exitUSER]I would like to book a taxi, please.[BOT]Sure, there are many results. What day do you want to leave to and what time are you like?<|endoftext|>\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ichat = InteractiveChat(model, tokenizer)\n",
    "ichat.start() # type exit if you want to stop the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should obtain a dialogue as following (not exactly the same)\n",
    "```\n",
    "User:  I'm looking for an hotel in center of cambridge for tonight\n",
    "Bot: Might I suggest the the University Arms Hotel, is rated 4 stars and has an excellent reputation and is rated 3 stars. \n",
    "User:  How much is it?\n",
    "Bot: The price range isn't listed. Is there another type of cuisine you might like?\n",
    "```\n",
    "However all answer are not relevant !!! \n",
    "\n",
    "**Let consider in the following evaluating the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.The MULTIWoZ corpus\n",
    "\n",
    "The Multi-domain Wizard-of-Oz (MultiWOZ) dataset is a large-scale human-human conversational corpus spanning over seven domains, containing 8438 multi-turn dialogues, with each dialogue averaging 14 turns. Different from existing standard datasets like WOZ and DSTC2, which contain less than 10 slots and only a few hundred values, MultiWOZ has 30 (domain, slot) pairs and over 4,500 possible values. The dialogues span seven domains: restaurant, hotel, attraction, taxi, train, hospital and police. \n",
    "\n",
    "### Objective \n",
    "* Looking at the data ([lik-here](https://github.com/budzianowski/multiwoz) for original repository)\n",
    "* Evaluate the generative model\n",
    "* Discuss what are missing for a complete chatbot\n",
    "* Improving the generation : notice for this last part you are free to use any model you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# woz_dataset\n",
    "woz_dataset = load_dataset(\"multi_woz_v22\")\n",
    "training_set = woz_dataset['train']\n",
    "validation_set = woz_dataset['validation']\n",
    "test_set = woz_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue_id': 'PMUL4398.json',\n",
       " 'services': ['restaurant', 'hotel'],\n",
       " 'turns': {'turn_id': ['0',\n",
       "   '1',\n",
       "   '2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '6',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '10',\n",
       "   '11'],\n",
       "  'speaker': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
       "  'utterance': ['i need a place to dine in the center thats expensive',\n",
       "   'I have several options for you; do you prefer African, Asian, or British food?',\n",
       "   'Any sort of food would be fine, as long as it is a bit expensive. Could I get the phone number for your recommendation?',\n",
       "   'There is an Afrian place named Bedouin in the centre. How does that sound?',\n",
       "   'Sounds good, could I get that phone number? Also, could you recommend me an expensive hotel?',\n",
       "   \"Bedouin's phone is 01223367660. As far as hotels go, I recommend the University Arms Hotel in the center of town.\",\n",
       "   'Yes. Can you book it for me?',\n",
       "   'Sure, when would you like that reservation?',\n",
       "   'i want to book it for 2 people and 2 nights starting from saturday.',\n",
       "   'Your booking was successful. Your reference number is FRGZWQL2 . May I help you further?',\n",
       "   'That is all I need to know. Thanks, good bye.',\n",
       "   'Thank you so much for Cambridge TownInfo centre. Have a great day!'],\n",
       "  'frames': [{'service': ['restaurant', 'hotel'],\n",
       "    'state': [{'active_intent': 'find_restaurant',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': ['restaurant-area',\n",
       "        'restaurant-pricerange'],\n",
       "       'slots_values_list': [['centre'], ['expensive']]}},\n",
       "     {'active_intent': 'find_hotel',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': [], 'slots_values_list': []}}],\n",
       "    'slots': [{'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []},\n",
       "     {'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': ['restaurant', 'hotel'],\n",
       "    'state': [{'active_intent': 'find_restaurant',\n",
       "      'requested_slots': ['restaurant-food'],\n",
       "      'slots_values': {'slots_values_name': ['restaurant-area',\n",
       "        'restaurant-pricerange'],\n",
       "       'slots_values_list': [['centre'], ['expensive']]}},\n",
       "     {'active_intent': 'find_hotel',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': [], 'slots_values_list': []}}],\n",
       "    'slots': [{'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []},\n",
       "     {'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': ['restaurant', 'hotel'],\n",
       "    'state': [{'active_intent': 'find_restaurant',\n",
       "      'requested_slots': ['restaurant-phone'],\n",
       "      'slots_values': {'slots_values_name': ['restaurant-area',\n",
       "        'restaurant-name',\n",
       "        'restaurant-pricerange'],\n",
       "       'slots_values_list': [['centre'], ['bedouin'], ['expensive']]}},\n",
       "     {'active_intent': 'find_hotel',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': ['hotel-pricerange', 'hotel-type'],\n",
       "       'slots_values_list': [['expensive'], ['hotel']]}}],\n",
       "    'slots': [{'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []},\n",
       "     {'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': ['hotel'],\n",
       "    'state': [{'active_intent': 'find_hotel',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': ['hotel-name',\n",
       "        'hotel-pricerange',\n",
       "        'hotel-type'],\n",
       "       'slots_values_list': [['university arms hotel'],\n",
       "        ['expensive'],\n",
       "        ['hotel']]}}],\n",
       "    'slots': [{'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': ['hotel'],\n",
       "    'state': [{'active_intent': 'book_hotel',\n",
       "      'requested_slots': [],\n",
       "      'slots_values': {'slots_values_name': ['hotel-bookday',\n",
       "        'hotel-bookpeople',\n",
       "        'hotel-bookstay',\n",
       "        'hotel-name',\n",
       "        'hotel-pricerange',\n",
       "        'hotel-type'],\n",
       "       'slots_values_list': [['saturday'],\n",
       "        ['2'],\n",
       "        ['2'],\n",
       "        ['university arms hotel'],\n",
       "        ['expensive'],\n",
       "        ['hotel']]}}],\n",
       "    'slots': [{'slot': [],\n",
       "      'value': [],\n",
       "      'start': [],\n",
       "      'exclusive_end': [],\n",
       "      'copy_from': [],\n",
       "      'copy_from_value': []}]},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': [], 'state': [], 'slots': []},\n",
       "   {'service': [], 'state': [], 'slots': []}],\n",
       "  'dialogue_acts': [{'dialog_act': {'act_type': ['Restaurant-Inform'],\n",
       "     'act_slots': [{'slot_name': ['area', 'pricerange'],\n",
       "       'slot_value': ['centre', 'expensive']}]},\n",
       "    'span_info': {'act_type': ['Restaurant-Inform', 'Restaurant-Inform'],\n",
       "     'act_slot_name': ['area', 'pricerange'],\n",
       "     'act_slot_value': ['centre', 'expensive'],\n",
       "     'span_start': [30, 43],\n",
       "     'span_end': [36, 52]}},\n",
       "   {'dialog_act': {'act_type': ['Restaurant-Inform', 'Restaurant-Select'],\n",
       "     'act_slots': [{'slot_name': ['choice'], 'slot_value': ['several']},\n",
       "      {'slot_name': ['food', 'food', 'food'],\n",
       "       'slot_value': ['African', 'Asian', 'British']}]},\n",
       "    'span_info': {'act_type': ['Restaurant-Inform',\n",
       "      'Restaurant-Select',\n",
       "      'Restaurant-Select',\n",
       "      'Restaurant-Select'],\n",
       "     'act_slot_name': ['choice', 'food', 'food', 'food'],\n",
       "     'act_slot_value': ['several', 'African', 'Asian', 'British'],\n",
       "     'span_start': [7, 46, 55, 65],\n",
       "     'span_end': [14, 53, 60, 72]}},\n",
       "   {'dialog_act': {'act_type': ['Restaurant-Request'],\n",
       "     'act_slots': [{'slot_name': ['food'], 'slot_value': ['?']}]},\n",
       "    'span_info': {'act_type': [],\n",
       "     'act_slot_name': [],\n",
       "     'act_slot_value': [],\n",
       "     'span_start': [],\n",
       "     'span_end': []}},\n",
       "   {'dialog_act': {'act_type': ['Restaurant-Inform'],\n",
       "     'act_slots': [{'slot_name': ['area', 'food', 'name'],\n",
       "       'slot_value': ['centre', 'Afrian', 'Bedouin']}]},\n",
       "    'span_info': {'act_type': ['Restaurant-Inform',\n",
       "      'Restaurant-Inform',\n",
       "      'Restaurant-Inform'],\n",
       "     'act_slot_name': ['food', 'name', 'area'],\n",
       "     'act_slot_value': ['Afrian', 'Bedouin', 'centre'],\n",
       "     'span_start': [12, 31, 46],\n",
       "     'span_end': [18, 38, 52]}},\n",
       "   {'dialog_act': {'act_type': ['Hotel-Inform', 'Restaurant-Request'],\n",
       "     'act_slots': [{'slot_name': ['pricerange', 'type'],\n",
       "       'slot_value': ['expensive', 'hotel']},\n",
       "      {'slot_name': ['phone'], 'slot_value': ['?']}]},\n",
       "    'span_info': {'act_type': ['Hotel-Inform', 'Hotel-Inform'],\n",
       "     'act_slot_name': ['pricerange', 'type'],\n",
       "     'act_slot_value': ['expensive', 'hotel'],\n",
       "     'span_start': [76, 86],\n",
       "     'span_end': [85, 91]}},\n",
       "   {'dialog_act': {'act_type': ['Hotel-Recommend', 'Restaurant-Inform'],\n",
       "     'act_slots': [{'slot_name': ['area', 'name'],\n",
       "       'slot_value': ['center of town', 'the University Arms Hotel']},\n",
       "      {'slot_name': ['name', 'phone'],\n",
       "       'slot_value': ['Bedouin', '01223367660']}]},\n",
       "    'span_info': {'act_type': ['Restaurant-Inform',\n",
       "      'Restaurant-Inform',\n",
       "      'Hotel-Recommend',\n",
       "      'Hotel-Recommend'],\n",
       "     'act_slot_name': ['name', 'phone', 'name', 'area'],\n",
       "     'act_slot_value': ['Bedouin',\n",
       "      '01223367660',\n",
       "      'the University Arms Hotel',\n",
       "      'center of town'],\n",
       "     'span_start': [0, 19, 65, 98],\n",
       "     'span_end': [7, 30, 90, 112]}},\n",
       "   {'dialog_act': {'act_type': ['Hotel-Inform'],\n",
       "     'act_slots': [{'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': [],\n",
       "     'act_slot_name': [],\n",
       "     'act_slot_value': [],\n",
       "     'span_start': [],\n",
       "     'span_end': []}},\n",
       "   {'dialog_act': {'act_type': ['Booking-Request'],\n",
       "     'act_slots': [{'slot_name': ['bookday'], 'slot_value': ['?']}]},\n",
       "    'span_info': {'act_type': [],\n",
       "     'act_slot_name': [],\n",
       "     'act_slot_value': [],\n",
       "     'span_start': [],\n",
       "     'span_end': []}},\n",
       "   {'dialog_act': {'act_type': ['Hotel-Inform'],\n",
       "     'act_slots': [{'slot_name': ['bookday', 'bookpeople', 'bookstay'],\n",
       "       'slot_value': ['saturday', '2', '2']}]},\n",
       "    'span_info': {'act_type': ['Hotel-Inform', 'Hotel-Inform', 'Hotel-Inform'],\n",
       "     'act_slot_name': ['bookstay', 'bookpeople', 'bookday'],\n",
       "     'act_slot_value': ['2', '2', 'saturday'],\n",
       "     'span_start': [22, 35, 58],\n",
       "     'span_end': [23, 36, 66]}},\n",
       "   {'dialog_act': {'act_type': ['Booking-Book', 'general-reqmore'],\n",
       "     'act_slots': [{'slot_name': ['ref'], 'slot_value': ['FRGZWQL2']},\n",
       "      {'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': ['Booking-Book'],\n",
       "     'act_slot_name': ['ref'],\n",
       "     'act_slot_value': ['FRGZWQL2'],\n",
       "     'span_start': [54],\n",
       "     'span_end': [62]}},\n",
       "   {'dialog_act': {'act_type': ['general-bye'],\n",
       "     'act_slots': [{'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': [],\n",
       "     'act_slot_name': [],\n",
       "     'act_slot_value': [],\n",
       "     'span_start': [],\n",
       "     'span_end': []}},\n",
       "   {'dialog_act': {'act_type': ['general-bye', 'general-welcome'],\n",
       "     'act_slots': [{'slot_name': ['none'], 'slot_value': ['none']},\n",
       "      {'slot_name': ['none'], 'slot_value': ['none']}]},\n",
       "    'span_info': {'act_type': [],\n",
       "     'act_slot_name': [],\n",
       "     'act_slot_value': [],\n",
       "     'span_start': [],\n",
       "     'span_end': []}}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yeah, could you recommend a good gastropub?',\n",
       " \"Backstreet Bistro. It's expensive though. There is a moderately priced one called The Cow Pizza Kitchen and Bar if preferred.\",\n",
       " 'I would like to book a table at the Backstreet Bistro for 5 people at 16:00 on Thursday.',\n",
       " 'No problem. That is booked for you and your reference number is 2VE84YC5 . Is there anything else I can book for you?',\n",
       " 'Yes, any suggestions of museums found in the east area of town?',\n",
       " 'Yes, Gallery at Twelve a High Street is excellent, and has free admission. Would you like more information?',\n",
       " 'Can I please have the phone number and address for that place?',\n",
       " 'Certainly! The address for gallery at twelve a high street is fulbourn and the phone number is 01223295264. Can I help you with anything else?',\n",
       " \"Great that's all the information I needed today, thank you!\",\n",
       " 'You are very welcome. Have a nice day. Good bye.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[10]['turns']['utterance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1 Get all the tuple of the test set \n",
    "\n",
    "Create a Dataframe with two columns, one containing the column of the user query and the other containing the bot answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_query = []\n",
    "bot_answer = []\n",
    "\n",
    "# create a dataframe with two columns : user_query and bot_answer\n",
    "for i in range(len(test_set)):\n",
    "    for j in range(0, len(test_set[i]['turns']['utterance']), 2):\n",
    "        try:\n",
    "            user_query.append(test_set[i]['turns']['utterance'][j])\n",
    "            bot_answer.append(test_set[i]['turns']['utterance'][j+1])\n",
    "        except:\n",
    "            raise Exception(\"It might be that the amount of user queries and bot answers are not the same.\")\n",
    "\n",
    "df = pd.DataFrame({'user_query': user_query, 'bot_answer':bot_answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_query</th>\n",
       "      <th>bot_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I need train reservations from norwich to camb...</td>\n",
       "      <td>I have 133 trains matching your request. Is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like to leave on Monday and arrive by 18:00.</td>\n",
       "      <td>There are 12 trains for the day and time you r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before booking, I would also like to know the ...</td>\n",
       "      <td>There are 12 trains meeting your needs with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No hold off on booking for now. Can you help m...</td>\n",
       "      <td>Yes it is a cinema located in the south part o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes, that was all I needed. Thank you very much!</td>\n",
       "      <td>Thank you for using our system.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7367</th>\n",
       "      <td>A swimming pool sounds like much more fun, doe...</td>\n",
       "      <td>There are four pools, abbey pool and astroturf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7368</th>\n",
       "      <td>Any one of those is fine. May I get the entran...</td>\n",
       "      <td>I'm, sorry, but the entrance fee is not listed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7369</th>\n",
       "      <td>Yes. I am also looking for a train, leaving on...</td>\n",
       "      <td>TR5648 will be departing cambridge Friday at 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7370</th>\n",
       "      <td>That will work. Can I have this booking for si...</td>\n",
       "      <td>I've booked that. Your reference number is 0IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>Great thank you that should be all</td>\n",
       "      <td>Thank you, have a great day.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7372 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             user_query  \\\n",
       "0     I need train reservations from norwich to camb...   \n",
       "1      I'd like to leave on Monday and arrive by 18:00.   \n",
       "2     Before booking, I would also like to know the ...   \n",
       "3     No hold off on booking for now. Can you help m...   \n",
       "4      Yes, that was all I needed. Thank you very much!   \n",
       "...                                                 ...   \n",
       "7367  A swimming pool sounds like much more fun, doe...   \n",
       "7368  Any one of those is fine. May I get the entran...   \n",
       "7369  Yes. I am also looking for a train, leaving on...   \n",
       "7370  That will work. Can I have this booking for si...   \n",
       "7371                 Great thank you that should be all   \n",
       "\n",
       "                                             bot_answer  \n",
       "0     I have 133 trains matching your request. Is th...  \n",
       "1     There are 12 trains for the day and time you r...  \n",
       "2     There are 12 trains meeting your needs with th...  \n",
       "3     Yes it is a cinema located in the south part o...  \n",
       "4                       Thank you for using our system.  \n",
       "...                                                 ...  \n",
       "7367  There are four pools, abbey pool and astroturf...  \n",
       "7368  I'm, sorry, but the entrance fee is not listed...  \n",
       "7369  TR5648 will be departing cambridge Friday at 1...  \n",
       "7370  I've booked that. Your reference number is 0IC...  \n",
       "7371                       Thank you, have a great day.  \n",
       "\n",
       "[7372 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 Generate the different output for user query\n",
    "Select the 50 first lines (if you get access to gpus you can try to generate all answers) and generates from user_query a bot answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSnXat8sv3a8",
    "outputId": "20827573-2211-4590-b96b-72eb10471648",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_top_50 = df.head(50)\n",
    "\n",
    "#generate the bot answers\n",
    "bot_answers = []\n",
    "for i in range(len(df_top_50)):\n",
    "    bot_answers.append(ichat.answer(df_top_50['user_query'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only the text from the bot answers\n",
    "bot_answers_trimmed = [bot_answer.split(\"[BOT]\")[1][:-13] if len(bot_answer.split(\"[BOT]\"))>1 else '' for bot_answer in bot_answers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I need train reservations from norwich to cambridge\n",
      "Expected answer: I have 133 trains matching your request. Is there a specific day and time you would like to travel?\n",
      "Generated answer: the TR6065 leaves at 2:50 and gets to cambridge at 2:07. does that work?\n",
      "__________________________________________________\n",
      "Query: I'd like to leave on Monday and arrive by 18:00.\n",
      "Expected answer: There are 12 trains for the day and time you request. Would you like to book it now?\n",
      "Generated answer: I have the cambridge passenger byard park and the hotel booked for you for that reservation.\n",
      "__________________________________________________\n",
      "Query: Before booking, I would also like to know the travel time, price, and departure time please.\n",
      "Expected answer: There are 12 trains meeting your needs with the first leaving at 05:16 and the last one leaving at 16:16. Do you want to book one of these?\n",
      "Generated answer: The first train leaves at 8:24, the price is 30.24 pounds. The travel time is 105 minutes and the travel time is 163 minutes. Is there anything else I can help with?\n",
      "__________________________________________________\n",
      "Query: No hold off on booking for now. Can you help me find an attraction called cineworld cinema?\n",
      "Expected answer: Yes it is a cinema located in the south part of town what information would you like on it?\n",
      "Generated answer: Cineworld College is an International college located in the east. Would you like to reserve a seat?\n",
      "__________________________________________________\n",
      "Query: Yes, that was all I needed. Thank you very much!\n",
      "Expected answer: Thank you for using our system.\n",
      "Generated answer: Okay thank you. Enjoy your dining experience. Goodbye!\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#print 10 queries and answers and expected answers\n",
    "for i in range(5):\n",
    "    print(f\"Query: {df_top_50['user_query'][i]}\")\n",
    "    print(f\"Expected answer: {df_top_50['bot_answer'][i]}\")\n",
    "    print(f\"Generated answer: {bot_answers_trimmed[i]}\")\n",
    "    print(\"_\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3 Evaluate the performance of the system\n",
    "You can now evaluate the performance of the systems on the generated sample you get. **You will try two metrics :**\n",
    "* A First approach base on common words between the ground truth and the generation\n",
    "* You are free to chose the second approach (BERTScore, ROUGE, BLEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XKKKfs6wUE5",
    "outputId": "37bbfd14-a4c8-4983-918c-f9ab0db743c8"
   },
   "outputs": [],
   "source": [
    "sets_words_predicted = []\n",
    "sets_words_real = []\n",
    "\n",
    "for i in range(len(df_top_50)):\n",
    "    try:\n",
    "        sets_words_predicted.append(set(bot_answers_trimmed[i].split(\" \")))\n",
    "    except:\n",
    "        # the bot answer is empty\n",
    "        sets_words_predicted.append(set())\n",
    "    sets_words_real.append(set(df_top_50['bot_answer'][i].split(\" \")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute percentage of common words between the predicted and the real answer for each query\n",
    "# this approach is vulnerable to a model that outputs the entire corpus as an answer\n",
    "common_percentage = []\n",
    "for i in range(len(df_top_50)):\n",
    "    common_percentage.append(len(sets_words_predicted[i].intersection(sets_words_real[i]))/len(sets_words_real[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of common words for all queries, on average, is: 0.190193836389502\n"
     ]
    }
   ],
   "source": [
    "common_average = sum(common_percentage)/len(common_percentage)\n",
    "print(f\"The percentage of common words for all queries, on average, is: {common_average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rouge score is: {'rouge1': 0.203994287302528, 'rouge2': 0.06592189857370122, 'rougeL': 0.17681741319591132, 'rougeLsum': 0.17521746242719677}\n"
     ]
    }
   ],
   "source": [
    "# use rouge score to evaluate the model's answers\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "rouge_score = rouge.compute(predictions=bot_answers_trimmed, references=df_top_50['bot_answer'])\n",
    "\n",
    "print(f\"The rouge score is: {rouge_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Improving performances\n",
    "\n",
    "**It is now up to you to improve the following model !!!**\n",
    "* You are free to choose any architecture/model (even pretrained one to improve performances)\n",
    "* You can add additional information in the input of the model\n",
    "* You will find in the annex how the model has been trained !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANNEXE : Training/Fine-Tuning Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "euhCckxZxNGN"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WoZGenerationDataset:\n",
    "    def __init__(self, dataset, window_size=3):\n",
    "        self.dataset = dataset\n",
    "        self.window_size = window_size\n",
    "        self.index = []\n",
    "        for i, dial in enumerate(dataset):\n",
    "            for j, speaker in enumerate(dial['turns']['speaker']):\n",
    "                if speaker == 1:\n",
    "                    self.index.append((i,j))\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        i, j = self.index[index]\n",
    "        dial = self.dataset[i]['turns']['utterance']\n",
    "\n",
    "        turns = dial[j-1] if(j!= 0) else ''\n",
    "        answer = dial[j]\n",
    "        return {'turns': turns,\n",
    "                'answer': answer}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm # The progress bar\n",
    "\n",
    "import torch # DeepLearning Framework\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM # Model repository\n",
    "from datasets import load_dataset # Dataset Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '<|endoftext|>'})\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFyuuKf4xcWK"
   },
   "source": [
    "## Implement the dataset module\n",
    "\n",
    "Create an object having as parent `torch.utils.data.dataset` implementing that return previous turn and answer of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KBvXWOVdyoFr"
   },
   "outputs": [],
   "source": [
    "class DialogueCollator(Dataset):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, data):\n",
    "        input_tokens = self.tokenizer(['[USER]' + d['turns'] + \"[BOT]\" + d['answer'] for d in data],\n",
    "                                 return_tensors='pt', return_length=True, padding=True)\n",
    "        return {\n",
    "            'input_ids': input_tokens.input_ids,\n",
    "            'attention_mask': input_tokens.attention_mask\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ipmEgeiT0rAD"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, model, padding_idx=100):\n",
    "        self.model = model\n",
    "        self.optimizer = None\n",
    "\n",
    "    def at_training_start(self, learning_rate = 1e-3):\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=50257)\n",
    "\n",
    "    def validation_step(self, data):\n",
    "        y_pred = self.model(**data)\n",
    "        y_truth = data[\"input_ids\"][:, 1:].flatten()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_reconstruction = self.criterion(y_pred.logits[:,:-1].reshape(y_truth.shape[0], -1), y_truth)\n",
    "        return loss_reconstruction.item()\n",
    "\n",
    "    def training_step(self, data):\n",
    "        print(\"computing y_pred\")\n",
    "        y_pred = self.model(**data)\n",
    "        print(\"computed y_pred\")\n",
    "        y_truth = data[\"input_ids\"][:, 1:].flatten()\n",
    "        print(\"computed y_truth\")\n",
    "        loss_reconstruction = self.criterion(y_pred.logits[:,:-1].reshape(y_truth.shape[0], -1), y_truth)\n",
    "        print(\"computed loss\")\n",
    "        (loss_reconstruction).backward()\n",
    "        print(\"backpropagated\")\n",
    "        return loss_reconstruction.item()\n",
    "\n",
    "    def on_validation_end(self, resp):\n",
    "        print(f\"Validation loss is {resp}\")\n",
    "\n",
    "    def validation(self, validation_dl):\n",
    "        self.model.eval()\n",
    "        loss_buffer = []\n",
    "        with torch.no_grad():\n",
    "            for data in validation_dl:\n",
    "                loss_buffer.append(self.validation_step(data))\n",
    "        self.on_validation_end(np.mean(loss_buffer))\n",
    "        self.model.train()\n",
    "\n",
    "    def fit(self,\n",
    "            training_dl,\n",
    "            validation_dl,\n",
    "            learning_rate = 1e-3,\n",
    "            validation_frequency = 8,\n",
    "            max_iter = 10000,\n",
    "            use_gpu=False,\n",
    "\n",
    "        ):\n",
    "        if(use_gpu):\n",
    "          self.model = self.model.cuda()\n",
    "          print(\"using gpu\")\n",
    "        self.at_training_start(learning_rate)\n",
    "        iter_count = 0\n",
    "        loss_buffer = []\n",
    "        pbar = trange(max_iter)\n",
    "\n",
    "        step = 0\n",
    "        while(iter_count < max_iter):\n",
    "            for data in training_dl:\n",
    "                if use_gpu:\n",
    "                    data = {k:v.cuda() for k, v in data.items()}\n",
    "                    print(\"used gpu\")\n",
    "                self.optimizer.zero_grad()\n",
    "                print(\"zeroed grad\")\n",
    "                loss_buffer += [self.training_step(data)]\n",
    "                print(\"added loss to buffer\")\n",
    "                self.optimizer.step()\n",
    "                print(\"step = %d\"%step)\n",
    "                step += 1\n",
    "                if step > 100:\n",
    "                    return\n",
    "\n",
    "                if(iter_count  % validation_frequency == 0):\n",
    "                    print(\"Loss at iteration %s is %s\"%(iter_count, np.mean(loss_buffer)))\n",
    "                    self.validation(validation_dl)\n",
    "                    loss_buffer = []\n",
    "                iter_count += 1\n",
    "                pbar.update(1)\n",
    "                if(iter_count >= max_iter):\n",
    "                  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZNNjwKBmnfZk"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"multi_woz_v22\")\n",
    "\n",
    "training_set = WoZGenerationDataset(dataset['train'])\n",
    "collator = DialogueCollator(tokenizer)\n",
    "training_dl = DataLoader(training_set, batch_size=32, shuffle=True, collate_fn=collator, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(training_dl):\n",
    "    print(\"data at point %d\" %i)\n",
    "    print(data)\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am not sure why the dataloader is not working, but it seems I can not iterate over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506,
     "referenced_widgets": [
      "ad3d02f6521f4c54a92b23f1c34f4340",
      "de6ec2c4dece46e5824c27537d485771",
      "c96cb887dba54c72b44a48309982858c",
      "4adf23ada29f44b5b696cfd3933dffea",
      "ae0f4c56a3454aa8ad1373b68a72d93a",
      "144715c9b5b74737804151071fcf7c97",
      "f3bec5e14eca44fd9be26d8062eecd9e",
      "d90f3f793b5b42c3b551b1df34d471d4",
      "6c7b190f3941429cb21289e570c73d61",
      "935e276981b247248faf817c3743e30e",
      "9d83c3aafb4c4038b1c39685c8238414"
     ]
    },
    "id": "_wvY1TMAn1dh",
    "outputId": "f978d487-19fd-4d94-f119-2948e5c27bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1383da52a80e40f39da8ae4fb292433d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_gpu = False\n",
    "my_trainer = Trainer(model)\n",
    "my_trainer.fit(training_dl, None, validation_frequency=250, use_gpu=use_gpu, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6ymfF5TorsLW"
   },
   "outputs": [],
   "source": [
    "class Chatbot(object):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def answer(self, current_input):\n",
    "    return \"Not Implemented\"\n",
    "\n",
    "  def start(self):\n",
    "    current_answer = \"Start dialogue\"\n",
    "    current_input = \"\"\n",
    "    while(current_input != 'exit'):\n",
    "      current_input = input(\"Bot: \"+current_answer + \" \\nUser: \")\n",
    "      current_answer = self.answer(current_input)\n",
    "\n",
    "class ChitChat(Chatbot):\n",
    "  def __init__(self, model, tokenizer, collator, history_len = 1):\n",
    "    self.model = model\n",
    "    self.tokenizer = tokenizer\n",
    "    self.utterance = []\n",
    "    self.hlen = history_len\n",
    "\n",
    "  def answer(self, current_input):\n",
    "    self.utterance.append('[USER]'+current_input)\n",
    "    tokenized_text = self.tokenizer(''.join(self.utterance[max(0, len(self.utterance) - self.hlen): ]), return_tensors='pt')\n",
    "    generated_token_ids = self.model.generate(**tokenized_text, do_sample=True, max_length=200, pad_token_id=model.config.eos_token_id)[0]\n",
    "    answer = self.tokenizer.decode(generated_token_ids).split('[BOT]')[-1][:-len('<|endoftext|>')]\n",
    "    self.utterance.append('[BOT]'+answer)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Xkv9SHaxxoiJ"
   },
   "outputs": [],
   "source": [
    "cb = ChitChat(model.cpu(), tokenizer, collator, history_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "MduRYjM0x0Bk"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"ThomasGerald/wozchitchat\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ThomasGerald/wozchitchat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChitChat(Chatbot):\n",
    "  def __init__(self, model, tokenizer, history_len = 1):\n",
    "    self.model = model\n",
    "    self.tokenizer = tokenizer\n",
    "    self.utterance = []\n",
    "    self.hlen = history_len\n",
    "\n",
    "  def answer(self, current_input):\n",
    "    self.utterance.append('[USER]'+current_input)\n",
    "    tokenized_text = self.tokenizer(''.join(self.utterance[max(0, len(self.utterance) - self.hlen): ]), return_tensors='pt')\n",
    "    generated_token_ids = self.model.generate(**tokenized_text, do_sample=True, max_length=200, pad_token_id=model.config.eos_token_id)[0]\n",
    "    answer = self.tokenizer.decode(generated_token_ids).split('[BOT]')[-1][:-len('<|endoftext|>')].split('[USER]')[0]\n",
    "    self.utterance.append('[BOT]'+answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = ChitChat(model.cpu(), tokenizer, history_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Start dialogue \n",
      "User:  I'm looking for an hotel in center of cambridge for tonight\n",
      "Bot: Might I suggest the the University Arms Hotel, is rated 4 stars and has an excellent reputation and is rated 3 stars. \n",
      "User:  How much is it?\n",
      "Bot: The price range isn't listed. Is there another type of cuisine you might like? \n",
      "User:  exit\n"
     ]
    }
   ],
   "source": [
    "cb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMcm7ZIf8SKsTTPhRyWk3Ln",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "144715c9b5b74737804151071fcf7c97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4adf23ada29f44b5b696cfd3933dffea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_935e276981b247248faf817c3743e30e",
      "placeholder": "​",
      "style": "IPY_MODEL_9d83c3aafb4c4038b1c39685c8238414",
      "value": " 1053/2000 [13:55&lt;13:21,  1.18it/s]"
     }
    },
    "6c7b190f3941429cb21289e570c73d61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "935e276981b247248faf817c3743e30e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d83c3aafb4c4038b1c39685c8238414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad3d02f6521f4c54a92b23f1c34f4340": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de6ec2c4dece46e5824c27537d485771",
       "IPY_MODEL_c96cb887dba54c72b44a48309982858c",
       "IPY_MODEL_4adf23ada29f44b5b696cfd3933dffea"
      ],
      "layout": "IPY_MODEL_ae0f4c56a3454aa8ad1373b68a72d93a"
     }
    },
    "ae0f4c56a3454aa8ad1373b68a72d93a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96cb887dba54c72b44a48309982858c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d90f3f793b5b42c3b551b1df34d471d4",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c7b190f3941429cb21289e570c73d61",
      "value": 1053
     }
    },
    "d90f3f793b5b42c3b551b1df34d471d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6ec2c4dece46e5824c27537d485771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_144715c9b5b74737804151071fcf7c97",
      "placeholder": "​",
      "style": "IPY_MODEL_f3bec5e14eca44fd9be26d8062eecd9e",
      "value": " 53%"
     }
    },
    "f3bec5e14eca44fd9be26d8062eecd9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
