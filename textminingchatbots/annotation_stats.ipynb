{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to read BRAT and conll files\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_brat(folder_location):\n",
    "    ann_files = glob.glob(folder_location + \"*.ann\")\n",
    "\n",
    "    #read ann files and ignore lines starting with #\n",
    "    ann_lines = []\n",
    "    for ann_file in ann_files:\n",
    "        with open(ann_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if not line.startswith(\"#\"):\n",
    "                    ann_lines.append(line)\n",
    "\n",
    "    #split lines into things by tab, we want the second column as the type, third column as the entity\n",
    "    ann_lines_split = []\n",
    "    for line in ann_lines:\n",
    "        splits = line.split(\"\\t\")\n",
    "        ann_lines_split.append([splits[1].split(\" \")[0], splits[2].split(\"\\n\")[0]])\n",
    "    return ann_lines_split\n",
    "\n",
    "def read_conll(folder_location):\n",
    "    lines = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_annotations_brat(ann_lines_split):\n",
    "    #process the annotations into a dictionary of lists\n",
    "    #we want to get a dictionary count of tokens (entites split by space), a dictionary count of entities, and a dictionary count of entity types\n",
    "    count_entities = {}\n",
    "    count_tokens = {}\n",
    "    count_entity_types = {}\n",
    "\n",
    "    for line in ann_lines_split:\n",
    "        entity = line[1]\n",
    "        entity_type = line[0]\n",
    "        tokens = entity.split(\" \")\n",
    "        if entity in count_entities:\n",
    "            count_entities[entity] += 1\n",
    "        else:\n",
    "            count_entities[entity] = 1\n",
    "        for token in tokens:\n",
    "            if token in count_tokens:\n",
    "                count_tokens[token] += 1\n",
    "            else:\n",
    "                count_tokens[token] = 1\n",
    "        if entity_type in count_entity_types:\n",
    "            count_entity_types[entity_type] += 1\n",
    "        else:\n",
    "            count_entity_types[entity_type] = 1\n",
    "\n",
    "    # return total of tokens, total of entitities, total of unique entities, how many types we have and a dictionary of tokens per type count\n",
    "    return sum(count_tokens.values()), sum(count_entities.values()), len(count_entities), len(count_entity_types), count_entity_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read BRAT corpus EMEA trainset\n",
    "train_EMEA_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/train/EMEA/\"\n",
    "train_MEDLINE_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/train/MEDLINE/\"\n",
    "dev_EMEA_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/dev/EMEA/\"\n",
    "dev_MEDLINE_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/dev/MEDLINE/\"\n",
    "test_EMEA_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/test/EMEA/\"\n",
    "test_MEDLINE_folder_location = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed_BRAT/corpus/test/MEDLINE/\"\n",
    "\n",
    "folder_base = \"./QUAERO_FrenchMed_TP2021/QUAERO_FrenchMed\"\n",
    "\n",
    "formats = [\"conll\", \"brat\"]\n",
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "subsets = [\"EMEA\", \"MEDLINE\"]\n",
    "\n",
    "# create pandas dataframe to store results of number of tokens, number of entities, number of unique entities, number of entity types, and dictionary of entity types\n",
    "df = pd.DataFrame(columns=[\"format\", \"type\", \"subset\", \"tokens\", \"entities\", \"unique_entities\", \"entity_types\", \"entity_types_count\"])\n",
    "# add results to df\n",
    "for format in formats:\n",
    "    for splits in splits:\n",
    "        for subset in subsets:\n",
    "            if format == \"conll\":\n",
    "                folder = folder_base + \"_conll/corpus/\" + splits + \"/\" + subset + \"/\"\n",
    "                ann_lines_split = read_conll(folder)\n",
    "            elif format == \"brat\":\n",
    "                folder = folder_base + \"_BRAT/corpus/\" + splits + \"/\" + subset + \"/\"\n",
    "                ann_lines_split = read_brat(folder)\n",
    "            tokens, entities, unique_entities, entity_types, entity_types_count = process_annotations_brat(ann_lines_split)\n",
    "            df = df.append({\"format\": format, \"type\": \"tokens\", \"subset\": subset, \"tokens\": tokens, \"entities\": entities, \"unique_entities\": unique_entities, \"entity_types\": entity_types, \"entity_types_count\": entity_types_count}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_EMEA_ann_lines_split = read_brat(train_EMEA_folder_location)\n",
    "\n",
    "number_of_tokens, number_of_entities, number_of_unique_entities, number_of_entity_types, count_entity_types = process_annotations_brat(train_EMEA_ann_lines_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3579\n",
      "2695\n",
      "923\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(number_of_tokens)\n",
    "print(number_of_entities)\n",
    "print(number_of_unique_entities)\n",
    "print(number_of_entity_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
